{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b702097e",
   "metadata": {},
   "source": [
    "# Feature Engineering Notebook\n",
    "\n",
    "This notebook demonstrates feature extraction from physiological signals for stress detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our modules\n",
    "from preprocessing import preprocess_ecg, preprocess_eda, segment_signals\n",
    "from features import extract_time_domain_features, extract_frequency_domain_features, \\\n",
    "                     extract_eda_features, extract_accelerometer_features, extract_all_features\n",
    "from utils import load_dataset, save_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e9950",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, we'll create sample data\n",
    "# In practice, you would load your actual dataset\n",
    "sample_rate = 256  # Hz\n",
    "duration = 60  # seconds\n",
    "time_points = np.linspace(0, duration, duration * sample_rate)\n",
    "\n",
    "# Simulate ECG signal with stress-related changes\n",
    "# Baseline ECG\n",
    "ecg_baseline = np.sin(2 * np.pi * 1.2 * time_points) + 0.5 * np.random.normal(size=len(time_points))\n",
    "# Stress ECG (higher frequency, more variability)\n",
    "ecg_stress = np.sin(2 * np.pi * 1.8 * time_points) + 0.8 * np.random.normal(size=len(time_points))\n",
    "\n",
    "# Combine baseline and stress periods\n",
    "split_point = len(time_points) // 2\n",
    "ecg = np.concatenate([ecg_baseline[:split_point], ecg_stress[split_point:]])\n",
    "\n",
    "# Simulate EDA signal\n",
    "eda_baseline = 5 + 1 * np.sin(2 * np.pi * 0.05 * time_points) + np.random.normal(size=len(time_points))\n",
    "eda_stress = 7 + 2 * np.sin(2 * np.pi * 0.1 * time_points) + np.random.normal(size=len(time_points))\n",
    "eda = np.concatenate([eda_baseline[:split_point], eda_stress[split_point:]])\n",
    "\n",
    "# Simulate accelerometer data\n",
    "acc_x_baseline = np.random.normal(0, 0.1, size=len(time_points))\n",
    "acc_x_stress = np.random.normal(0, 0.3, size=len(time_points))\n",
    "acc_x = np.concatenate([acc_x_baseline[:split_point], acc_x_stress[split_point:]])\n",
    "\n",
    "acc_y_baseline = np.random.normal(0, 0.1, size=len(time_points))\n",
    "acc_y_stress = np.random.normal(0, 0.3, size=len(time_points))\n",
    "acc_y = np.concatenate([acc_y_baseline[:split_point], acc_y_stress[split_point:]])\n",
    "\n",
    "acc_z_baseline = 9.8 + np.random.normal(0, 0.1, size=len(time_points))\n",
    "acc_z_stress = 9.8 + np.random.normal(0, 0.3, size=len(time_points))\n",
    "acc_z = np.concatenate([acc_z_baseline[:split_point], acc_z_stress[split_point:]])\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'timestamp': time_points,\n",
    "    'ecg': ecg,\n",
    "    'eda': eda,\n",
    "    'acc_x': acc_x,\n",
    "    'acc_y': acc_y,\n",
    "    'acc_z': acc_z\n",
    "})\n",
    "\n",
    "print(\"Sample data created successfully!\")\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49698f81",
   "metadata": {},
   "source": [
    "## Preprocess Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ECG signal\n",
    "ecg_processed = preprocess_ecg(data['ecg'].values, sample_rate)\n",
    "if ecg_processed:\n",
    "    print(\"ECG preprocessing completed.\")\n",
    "    print(f\"Number of R-peaks detected: {len(ecg_processed['r_peaks'])}\")\n",
    "else:\n",
    "    print(\"ECG preprocessing failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess EDA signal\n",
    "eda_processed = preprocess_eda(data['eda'].values, sample_rate)\n",
    "if eda_processed:\n",
    "    print(\"EDA preprocessing completed.\")\n",
    "else:\n",
    "    print(\"EDA preprocessing failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c8823",
   "metadata": {},
   "source": [
    "## Segment Signals into Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a66de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment data into windows\n",
    "window_size = sample_rate * 30  # 30 seconds\n",
    "overlap = 0.5  # 50% overlap\n",
    "\n",
    "windows = segment_signals(data, window_size, overlap)\n",
    "print(f\"Segmented data into {len(windows)} windows of {window_size} samples each.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d2576",
   "metadata": {},
   "source": [
    "## Extract Features from Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65168716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from each window\n",
    "feature_list = []\n",
    "\n",
    "for i, window in enumerate(windows[:5]):  # Process first 5 windows for demo\n",
    "    print(f\"Processing window {i+1}/{len(windows)}\")\n",
    "    \n",
    "    # Extract all features\n",
    "    features = extract_all_features(window)\n",
    "    \n",
    "    # Add window information\n",
    "    features['window_id'] = i\n",
    "    \n",
    "    # Add artificial label for demonstration\n",
    "    # In practice, you would have actual labels\n",
    "    features['label'] = 1 if i >= len(windows[:5]) // 2 else 0  # Simulate stress in second half\n",
    "    \n",
    "    feature_list.append(features)\n",
    "\n",
    "if feature_list:\n",
    "    # Combine all features into a single DataFrame\n",
    "    features_df = pd.concat(feature_list, ignore_index=True)\n",
    "    print(f\"\\nExtracted features for {len(features_df)} windows.\")\n",
    "    print(f\"Features shape: {features_df.shape}\")\n",
    "    print(\"\\nFeature columns:\")\n",
    "    print(features_df.columns.tolist())\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst few rows of extracted features:\")\n",
    "    print(features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7650a",
   "metadata": {},
   "source": [
    "## Analyze Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ce2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of some key features\n",
    "if 'mean_eda' in features_df.columns and 'rmssd' in features_df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].hist(features_df['mean_eda'], bins=10, alpha=0.7)\n",
    "    axes[0].set_title('Distribution of Mean EDA')\n",
    "    axes[0].set_xlabel('Mean EDA (ÂµS)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    axes[1].hist(features_df['rmssd'], bins=10, alpha=0.7)\n",
    "    axes[1].set_title('Distribution of RMSSD')\n",
    "    axes[1].set_xlabel('RMSSD (ms)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20816373",
   "metadata": {},
   "source": [
    "## Save Processed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to processed data directory\n",
    "processed_dir = '../data/processed'\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "\n",
    "if 'features_df' in locals():\n",
    "    save_path = os.path.join(processed_dir, 'extracted_features.csv')\n",
    "    save_dataset(features_df, save_path)\n",
    "    print(f\"Features saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89291e",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After feature engineering, the next steps would be:\n",
    "1. Feature selection to identify the most relevant features\n",
    "2. Training and evaluating machine learning models\n",
    "3. Model optimization and validation\n",
    "\n",
    "Continue to the next notebook: `03-modeling.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
